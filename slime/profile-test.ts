import { readFileSync } from 'fs'
import Es6Parser from './packages/slime-parser/src/language/es2015/Es6Parser.ts'
import { es6Tokens } from './packages/slime-parser/src/language/es2015/Es6Tokens.ts'
import { SlimeCstToAst } from './packages/slime-parser/src/language/SlimeCstToAstUtil.ts'
import SlimeGenerator from './packages/slime-generator/src/SlimeGenerator.ts'
import SubhutiLexer from '../subhuti/src/parser/SubhutiLexer.ts'

// æ€§èƒ½åˆ†æå·¥å…· - æ‰¾å‡ºæœ€æ…¢çš„æ­¥éª¤
const testFile = process.argv[2] || 'tests/cases/single/24-map-set.js'

console.log(`\nğŸ” æ€§èƒ½åˆ†æ: ${testFile}\n`)

const code = readFileSync(testFile, 'utf-8')
const lines = code.split('\n').length
const bytes = Buffer.byteLength(code, 'utf-8')

console.log(`æ–‡ä»¶ä¿¡æ¯:`)
console.log(`  ä»£ç è¡Œæ•°: ${lines}`)
console.log(`  æ–‡ä»¶å¤§å°: ${bytes} bytes`)
console.log()

// 1. è¯æ³•åˆ†æ
console.time('1ï¸âƒ£ è¯æ³•åˆ†æ (Lexer)')
const lexer = new SubhutiLexer(es6Tokens)
const tokens = lexer.lexer(code)
console.timeEnd('1ï¸âƒ£ è¯æ³•åˆ†æ (Lexer)')
console.log(`  ç”Ÿæˆtokens: ${tokens.length}ä¸ª`)
console.log()

// 2. è¯­æ³•åˆ†æ
console.time('2ï¸âƒ£ è¯­æ³•åˆ†æ (Parser)')
const parser = new Es6Parser(tokens)
const cst = parser.Program()
console.timeEnd('2ï¸âƒ£ è¯­æ³•åˆ†æ (Parser)')
console.log(`  ç”ŸæˆCSTèŠ‚ç‚¹`)
console.log()

// 3. CST -> AST
console.time('3ï¸âƒ£ CSTè½¬AST (CstToAst)')
const slimeCstToAst = new SlimeCstToAst()
const ast = slimeCstToAst.toProgram(cst)
console.timeEnd('3ï¸âƒ£ CSTè½¬AST (CstToAst)')
console.log(`  ASTèŠ‚ç‚¹: ${ast.body.length}ä¸ªé¡¶å±‚è¯­å¥`)
console.log()

// 4. ä»£ç ç”Ÿæˆ
console.time('4ï¸âƒ£ ä»£ç ç”Ÿæˆ (Generator)')
const result = SlimeGenerator.generator(ast, tokens)
console.timeEnd('4ï¸âƒ£ ä»£ç ç”Ÿæˆ (Generator)')
console.log(`  ç”Ÿæˆä»£ç : ${result.code.length} bytes`)
console.log()

console.log('ğŸ“Š æ€§èƒ½æ¯”ç‡:')
console.log(`  å¤„ç†é€Ÿåº¦: ${(bytes / 1024).toFixed(2)} KB æ–‡ä»¶`)
console.log(`  æ¯è¡Œè€—æ—¶: ${((Date.now()) / lines).toFixed(2)} ms/è¡Œ`)

