/**
 * æµ‹è¯• Lexer å‰ç»åŠŸèƒ½
 * éªŒè¯ OptionalChaining çš„ lookahead æ˜¯å¦æ­£å¸¸å·¥ä½œ
 */

import SubhutiLexer from '../../../../../../subhuti/src/SubhutiLexer.ts'
import { es2025Tokens } from './Es2025Tokens.ts'

const lexer = new SubhutiLexer(es2025Tokens)

console.log('ğŸ§ª æµ‹è¯• Lexer å‰ç»åŠŸèƒ½\n')

// ============================================
// æµ‹è¯• 1ï¼šobj?.propï¼ˆæ­£å¸¸çš„ Optional Chainingï¼‰
// ============================================
console.log('ã€æµ‹è¯• 1ã€‘obj?.prop')
const tokens1 = lexer.tokenize('obj?.prop')
console.log('ç»“æœï¼š', tokens1.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))

const expected1 = ['Identifier(obj)', 'OptionalChaining(?.)', 'Identifier(prop)']
const actual1 = tokens1.map(t => `${t.tokenName}(${t.tokenValue})`)
const pass1 = JSON.stringify(expected1) === JSON.stringify(actual1)
console.log('æœŸæœ›ï¼š', expected1.join(' '))
console.log('çŠ¶æ€ï¼š', pass1 ? 'âœ… é€šè¿‡' : 'âŒ å¤±è´¥')
console.log()

// ============================================
// æµ‹è¯• 2ï¼ša ? .5 : 1ï¼ˆä¸‰å…ƒè¿ç®—ç¬¦ + æµ®ç‚¹æ•°ï¼‰
// ============================================
console.log('ã€æµ‹è¯• 2ã€‘a ? .5 : 1')
const tokens2 = lexer.tokenize('a ? .5 : 1')
console.log('ç»“æœï¼š', tokens2.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))

const expected2 = [
  'Identifier(a)',
  'Question(?)',         // â† ä¸æ˜¯ OptionalChaining
  'NumericLiteral(.5)',  // â† .5 æ˜¯æµ®ç‚¹æ•°
  'Colon(:)',
  'NumericLiteral(1)'
]
const actual2 = tokens2.map(t => `${t.tokenName}(${t.tokenValue})`)
const pass2 = JSON.stringify(expected2) === JSON.stringify(actual2)
console.log('æœŸæœ›ï¼š', expected2.join(' '))
console.log('çŠ¶æ€ï¼š', pass2 ? 'âœ… é€šè¿‡' : 'âŒ å¤±è´¥')
console.log()

// ============================================
// æµ‹è¯• 3ï¼šobj?.123ï¼ˆä¸åˆæ³•ï¼Œä½†æµ‹è¯•å‰ç»ï¼‰
// ============================================
console.log('ã€æµ‹è¯• 3ã€‘obj?.123')
const tokens3 = lexer.tokenize('obj?.123')
console.log('ç»“æœï¼š', tokens3.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))

const expected3 = [
  'Identifier(obj)',
  'Question(?)',          // â† å‰ç»æ‹’ç»äº† OptionalChaining
  'NumericLiteral(.123)'  // â† .123 æ˜¯æµ®ç‚¹æ•°
]
const actual3 = tokens3.map(t => `${t.tokenName}(${t.tokenValue})`)
const pass3 = JSON.stringify(expected3) === JSON.stringify(actual3)
console.log('æœŸæœ›ï¼š', expected3.join(' '))
console.log('çŠ¶æ€ï¼š', pass3 ? 'âœ… é€šè¿‡' : 'âŒ å¤±è´¥')
console.log()

// ============================================
// æµ‹è¯• 4ï¼šå¤æ‚åœºæ™¯
// ============================================
console.log('ã€æµ‹è¯• 4ã€‘result ? .value : 0')
const tokens4 = lexer.tokenize('result ? .value : 0')
console.log('ç»“æœï¼š', tokens4.map(t => `${t.tokenName}(${t.tokenValue})`).join(' '))

const expected4 = [
  'Identifier(result)',
  'Question(?)',
  'Dot(.)',
  'Identifier(value)',
  'Colon(:)',
  'NumericLiteral(0)'
]
const actual4 = tokens4.map(t => `${t.tokenName}(${t.tokenValue})`)
const pass4 = JSON.stringify(expected4) === JSON.stringify(actual4)
console.log('æœŸæœ›ï¼š', expected4.join(' '))
console.log('çŠ¶æ€ï¼š', pass4 ? 'âœ… é€šè¿‡' : 'âŒ å¤±è´¥')
console.log()

// ============================================
// æ€»ç»“
// ============================================
const totalTests = 4
const passedTests = [pass1, pass2, pass3, pass4].filter(Boolean).length

console.log('=' .repeat(60))
console.log(`æ€»è®¡ï¼š${passedTests}/${totalTests} æµ‹è¯•é€šè¿‡`)
console.log('=' .repeat(60))

if (passedTests === totalTests) {
  console.log('ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼Lexer å‰ç»åŠŸèƒ½æ­£å¸¸å·¥ä½œï¼')
} else {
  console.log('âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦æ£€æŸ¥å®ç°')
  process.exit(1)
}

