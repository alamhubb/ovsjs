/**
 * Subhuti Parser - é«˜æ€§èƒ½ PEG Parser æ¡†æ¶
 *
 * æ ¸å¿ƒç‰¹æ€§ï¼š
 * - Packrat Parsingï¼ˆçº¿æ€§æ—¶é—´å¤æ‚åº¦ï¼ŒLRU ç¼“å­˜ï¼‰
 * - è¿”å›å€¼è¯­ä¹‰ï¼ˆæˆåŠŸè¿”å› CSTï¼Œå¤±è´¥è¿”å› undefinedï¼‰
 *
 * æ¶æ„è®¾è®¡ï¼š
 * - ç»§æ‰¿ SubhutiTokenLookaheadï¼ˆå‰ç»èƒ½åŠ›ï¼‰
 * - å®ç° ITokenConsumerContextï¼ˆæä¾›æ¶ˆè´¹æ¥å£ï¼‰
 * - æ”¯æŒæ³›å‹æ‰©å±• SubhutiTokenConsumer
 *
 * @version 5.0.0
 */

import SubhutiTokenLookahead from "./SubhutiTokenLookahead.ts"
import SubhutiCst from "./struct/SubhutiCst.ts";
import type SubhutiMatchToken from "./struct/SubhutiMatchToken.ts";
import {SubhutiErrorHandler, ParsingError} from "./SubhutiError.ts";
import {SubhutiTraceDebugger} from "./SubhutiDebug.ts";
import {SubhutiPackratCache, type SubhutiPackratCacheResult} from "./SubhutiPackratCache.ts";
import SubhutiTokenConsumer from "./SubhutiTokenConsumer.ts";
import {SubhutiDebugRuleTracePrint} from "./SubhutiDebugRuleTracePrint.ts";

// Grammar Validation
import {SubhutiGrammarValidator} from "./validation/SubhutiGrammarValidator";

// ============================================
// ç±»å‹å®šä¹‰
// ============================================

export type RuleFunction = () => SubhutiCst | undefined

export interface SubhutiParserOr {
    alt: RuleFunction
}

export interface SubhutiBackData {
    tokenIndex: number
    curCstChildrenLength: number
}

/**
 * éƒ¨åˆ†åŒ¹é…è®°å½•ï¼ˆç”¨äºå®¹é”™æ¨¡å¼ï¼‰
 * åœ¨å›æº¯æ—¶è®°å½•å·²æ¶ˆè´¹ token çš„ CST ç»“æ„
 */
export interface PartialMatchRecord {
    children: SubhutiCst[]    // éƒ¨åˆ†åŒ¹é…çš„ childrenï¼ˆå¼•ç”¨ï¼‰
    parentCst: SubhutiCst     // çˆ¶èŠ‚ç‚¹ï¼ˆæ¢å¤æ—¶æŠŠ children æ”¾åˆ°è¿™é‡Œï¼‰
    endTokenIndex: number     // æ¶ˆè€—åˆ°çš„ token ä½ç½®
    startTokenIndex: number   // èµ·å§‹ token ä½ç½®
}

/**
 * è§£æè®°å½•æ ‘èŠ‚ç‚¹ï¼ˆç”¨äºå®¹é”™æ¨¡å¼ï¼‰
 * åªå¢ä¸åˆ ï¼Œè®°å½•æ‰€æœ‰è§£æå°è¯•è·¯å¾„
 */
export interface ParseRecordNode {
    name: string                  // è§„åˆ™åæˆ– token å
    children: ParseRecordNode[]   // å­èŠ‚ç‚¹ï¼ˆåªå¢ä¸åˆ ï¼‰
    startTokenIndex: number       // è¯¥èŠ‚ç‚¹å¼€å§‹çš„ token ä½ç½®
    endTokenIndex: number         // è¯¥èŠ‚ç‚¹æ¶ˆè€—åˆ°çš„ token ä½ç½®
    token?: SubhutiMatchToken     // å¦‚æœæ˜¯ token å¶å­èŠ‚ç‚¹
    value?: string                // token å€¼
}

// ============================================
// è£…é¥°å™¨ç³»ç»Ÿ
// ============================================

export function Subhuti<E extends SubhutiTokenLookahead, T extends new (...args: any[]) => SubhutiParser<E>>(
    target: T,
    context: ClassDecoratorContext
) {
    context.metadata.className = target.name
    return target
}

export function SubhutiRule(targetFun: any, context: ClassMethodDecoratorContext) {
    const ruleName = targetFun.name
    const className = context.metadata.className

    const wrappedFunction = function (...args: any[]): SubhutiCst | undefined {
        return this.executeRuleWrapper(targetFun, ruleName, className, ...args)
    }

    Object.defineProperty(wrappedFunction, 'name', {value: ruleName})

    // âœ… ä¿å­˜åŸå§‹å‡½æ•°å¼•ç”¨ï¼ˆä¾› SubhutiRuleCollector ä½¿ç”¨ï¼‰
    Object.defineProperty(wrappedFunction, '__originalFunction__', {
        value: targetFun,
        writable: false,
        enumerable: false,
        configurable: false
    })

    // âœ… æ·»åŠ å…ƒæ•°æ®æ ‡è®°ï¼Œæ ‡è¯†è¿™æ˜¯ä¸€ä¸ªè§„åˆ™æ–¹æ³•
    Object.defineProperty(wrappedFunction, '__isSubhutiRule__', {
        value: true,
        writable: false,
        enumerable: false,
        configurable: false
    })

    return wrappedFunction
}

export type SubhutiTokenConsumerConstructor<T extends SubhutiTokenConsumer> =
    new (parser: SubhutiParser) => T

/**
 * Parser æ„é€ é€‰é¡¹
 */
export interface SubhutiParserOptions<T extends SubhutiTokenConsumer = SubhutiTokenConsumer> {
    /** TokenConsumer ç±»ï¼ˆå¯é€‰ï¼‰ */
    tokenConsumer?: SubhutiTokenConsumerConstructor<T>
}

// ============================================
// SubhutiParser æ ¸å¿ƒç±»
// ============================================

export default class SubhutiParser<T extends SubhutiTokenConsumer = SubhutiTokenConsumer>
    extends SubhutiTokenLookahead {
    // æ ¸å¿ƒå­—æ®µ
    readonly tokenConsumer: T

    private readonly cstStack: SubhutiCst[] = []
    private readonly className: string

    /**
     * åˆ†ææ¨¡å¼æ ‡å¿—
     * - true: åˆ†ææ¨¡å¼ï¼ˆç”¨äºè¯­æ³•éªŒè¯ï¼Œä¸æŠ›å¼‚å¸¸ï¼‰
     * - false: æ­£å¸¸æ¨¡å¼ï¼ˆç”¨äºè§£æï¼ŒæŠ›å¼‚å¸¸ï¼‰
     */
    private _analysisMode: boolean = false

    /**
     * å®¹é”™æ¨¡å¼æ ‡å¿—
     * - true: å¯ç”¨å®¹é”™ï¼ˆè§£æå¤±è´¥æ—¶è·³è¿‡ token ç»§ç»­è§£æï¼‰
     * - false: ä¸å¯ç”¨å®¹é”™ï¼ˆè§£æå¤±è´¥æ—¶åœæ­¢ï¼‰
     */
    private _errorRecoveryMode: boolean = false

    /**
     * åŒæ­¥ç‚¹ Token åç§°é›†åˆ
     * è¿™äº› token é€šå¸¸æ˜¯è¯­å¥çš„å¼€å§‹ï¼Œç”¨äºå®¹é”™æ¨¡å¼ä¸‹çš„æ¢å¤ç‚¹
     */
    protected _syncTokens: Set<string> = new Set([
        'LetTok', 'ConstTok', 'VarTok',
        'FunctionTok', 'ClassTok', 'AsyncTok',
        'IfTok', 'ForTok', 'WhileTok', 'DoTok', 'SwitchTok',
        'TryTok', 'ThrowTok', 'ReturnTok', 'BreakTok', 'ContinueTok',
        'ImportTok', 'ExportTok',
        'DebuggerTok',
        'Semicolon',
    ])

    /**
     * è®¾ç½®åŒæ­¥ç‚¹ Token
     */
    setSyncTokens(tokens: string[]): this {
        this._syncTokens = new Set(tokens)
        return this
    }

    /**
     * æ·»åŠ åŒæ­¥ç‚¹ Token
     */
    addSyncTokens(tokens: string[]): this {
        for (const token of tokens) {
            this._syncTokens.add(token)
        }
        return this
    }

    /**
     * å¯ç”¨å®¹é”™æ¨¡å¼
     */
    enableErrorRecovery(): this {
        this._errorRecoveryMode = true
        return this
    }

    /**
     * è·å–å®¹é”™æ¨¡å¼çŠ¶æ€
     */
    get errorRecoveryMode(): boolean {
        return this._errorRecoveryMode
    }

    getRuleStack() {
        return this.cstStack.map(item => item.name)
    }

    // è°ƒè¯•å’Œé”™è¯¯å¤„ç†
    private _debugger?: SubhutiTraceDebugger
    private readonly _errorHandler = new SubhutiErrorHandler()

    // æ— é™å¾ªç¯æ£€æµ‹ï¼ˆè°ƒç”¨æ ˆçŠ¶æ€æ£€æµ‹ï¼‰
    /**
     * å¾ªç¯æ£€æµ‹é›†åˆï¼šO(1) æ£€æµ‹ (rule, position) æ˜¯å¦é‡å¤
     * æ ¼å¼: "ruleName:position"
     */
    private readonly loopDetectionSet: Set<string> = new Set()

    // Packrat Parsingï¼ˆé»˜è®¤ LRU ç¼“å­˜ï¼‰
    enableMemoization: boolean = true
    private readonly _cache: SubhutiPackratCache

    /**
     * éƒ¨åˆ†åŒ¹é…å€™é€‰åˆ—è¡¨ï¼ˆå®¹é”™æ¨¡å¼ä¸“ç”¨ï¼‰
     * è®°å½•åœ¨å›æº¯æ—¶è¢«åˆ é™¤ä½†æ¶ˆè´¹äº† token çš„ CST ç‰‡æ®µ
     */
    private _partialMatchCandidates: PartialMatchRecord[] = []

    /**
     * æœªè¢«è§£æçš„ tokens åˆ—è¡¨ï¼ˆå®¹é”™æ¨¡å¼ä¸“ç”¨ï¼‰
     * ç”¨äºæœ€ç»ˆåˆ¤æ–­è§£ææ˜¯å¦å®Œå…¨æˆåŠŸ
     */
    private _unparsedTokens: SubhutiMatchToken[] = []

    // ============================================
    // è§£æè®°å½•æ ‘ç›¸å…³ï¼ˆå®¹é”™æ¨¡å¼ä¸“ç”¨ï¼‰
    // ============================================

    /** è§£æè®°å½•æ ‘æ ¹èŠ‚ç‚¹ */
    private _parseRecordRoot: ParseRecordNode | null = null

    /** è§£æè®°å½•æ ‘èŠ‚ç‚¹æ ˆï¼ˆè·Ÿè¸ªå½“å‰è·¯å¾„ï¼‰ */
    private _parseRecordStack: ParseRecordNode[] = []

    /**
     * è·å–æœªè¢«è§£æçš„ tokens åˆ—è¡¨
     */
    get unparsedTokens(): SubhutiMatchToken[] {
        return this._unparsedTokens
    }

    /**
     * æ˜¯å¦æœ‰æœªè¢«è§£æçš„ tokens
     */
    get hasUnparsedTokens(): boolean {
        return this._unparsedTokens.length > 0
    }

    constructor(
        tokens: SubhutiMatchToken[] = [],
        optionsOrConsumer?: SubhutiTokenConsumerConstructor<T> | SubhutiParserOptions<T>,
    ) {
        super() // è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        this._tokens = tokens  // èµ‹å€¼ç»™çˆ¶ç±»çš„ _tokens
        this.tokenIndex = 0    // èµ‹å€¼ç»™çˆ¶ç±»çš„ tokenIndex
        this.className = this.constructor.name
        this._cache = new SubhutiPackratCache()

        // è§£æå‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
        let TokenConsumerClass: SubhutiTokenConsumerConstructor<T> | undefined

        if (optionsOrConsumer) {
            // åˆ¤æ–­æ˜¯ Class è¿˜æ˜¯ Options å¯¹è±¡
            if (typeof optionsOrConsumer === 'function') {
                // æ—§æ–¹å¼ï¼šç›´æ¥ä¼ å…¥ Class
                TokenConsumerClass = optionsOrConsumer
            } else {
                // æ–°æ–¹å¼ï¼šä¼ å…¥ options å¯¹è±¡
                TokenConsumerClass = optionsOrConsumer.tokenConsumer
            }
        }

        if (TokenConsumerClass) {
            this.tokenConsumer = new TokenConsumerClass(this)
        } else {
            this.tokenConsumer = new SubhutiTokenConsumer(this) as T
        }
    }

    // ============================================
    // å…¬å¼€ç»™ TokenConsumer ä½¿ç”¨çš„æ–¹æ³•
    // ============================================

    /**
     * ä¾› TokenConsumer ä½¿ç”¨çš„ consume æ–¹æ³•
     */
    _consumeToken(tokenName: string): SubhutiCst | undefined {
        return this.consume(tokenName)
    }

    /**
     * ä¾› TokenConsumer ä½¿ç”¨çš„æ ‡è®°è§£æå¤±è´¥æ–¹æ³•
     * ç”¨äºè½¯å…³é”®å­—æ£€æŸ¥å¤±è´¥æ—¶æ ‡è®°è§£æå¤±è´¥
     */
    _markParseFail(): void {
        this._parseSuccess = false
    }

    // ============================================
    // Parser å†…éƒ¨ Getter
    // ============================================

    get curCst(): SubhutiCst | undefined {
        return this.cstStack[this.cstStack.length - 1]
    }

    // å…¬å¼€æ–¹æ³•
    setTokens(tokens: SubhutiMatchToken[]): void {
        this._tokens.length = 0
        this._tokens.push(...tokens)
        this.tokenIndex = 0
        this._cache.clear()
    }

    // åŠŸèƒ½å¼€å…³ï¼ˆé“¾å¼è°ƒç”¨ï¼‰
    cache(enable: boolean = true): this {
        this.enableMemoization = enable
        return this
    }

    debug(): this {
        this._debugger = new SubhutiTraceDebugger(this._tokens)
        return this
    }

    errorHandler(enable: boolean = true): this {
        this._errorHandler.setDetailed(enable)
        return this
    }

    /**
     * å¯ç”¨åˆ†ææ¨¡å¼ï¼ˆç”¨äºè¯­æ³•éªŒè¯ï¼Œä¸æŠ›å¼‚å¸¸ï¼‰
     *
     * åœ¨åˆ†ææ¨¡å¼ä¸‹ï¼š
     * - ä¸æŠ›å‡ºå·¦é€’å½’å¼‚å¸¸
     * - ä¸æŠ›å‡ºæ— é™å¾ªç¯å¼‚å¸¸
     * - ä¸æŠ›å‡º Token æ¶ˆè´¹å¤±è´¥å¼‚å¸¸
     * - ä¸æŠ›å‡º EOF æ£€æµ‹å¼‚å¸¸
     *
     * @internal ä»…ä¾› SubhutiRuleCollector ä½¿ç”¨
     */
    enableAnalysisMode(): void {
        this._analysisMode = true
    }

    /**
     * ç¦ç”¨åˆ†ææ¨¡å¼ï¼ˆæ¢å¤æ­£å¸¸æ¨¡å¼ï¼‰
     *
     * @internal ä»…ä¾› SubhutiRuleCollector ä½¿ç”¨
     */
    disableAnalysisMode(): void {
        this._analysisMode = false
    }

    /**
     * å¯ç”¨è¯­æ³•éªŒè¯ï¼ˆé“¾å¼è°ƒç”¨ï¼‰ï¼ŒéªŒè¯è¯­æ³•ï¼ˆæ£€æµ‹ Or è§„åˆ™å†²çªï¼‰
     *
     * ç”¨æ³•ï¼š
     * ```typescript
     * const parser = new Es2025Parser(tokens).validate()
     * const cst = parser.Script()
     * ```
     *
     * @returns this - æ”¯æŒé“¾å¼è°ƒç”¨
     * @throws SubhutiGrammarValidationError - è¯­æ³•æœ‰å†²çªæ—¶æŠ›å‡º
     */
    validate(): this {
        SubhutiGrammarValidator.validate(this)
        return this
    }

    /**
     * æ£€æµ‹æ˜¯å¦æ˜¯ç›´æ¥æˆ–é—´æ¥å·¦é€’å½’
     *
     * âœ… è¿™ä¸ªæ–¹æ³•å¯ä»¥å‡†ç¡®åˆ¤æ–­å·¦é€’å½’
     * âŒ ä¸èƒ½åˆ¤æ–­æ˜¯å¦æ˜¯ Or åˆ†æ”¯é®è”½ï¼ˆè¿”å› false åªè¡¨ç¤ºä¸æ˜¯å·¦é€’å½’ï¼‰
     *
     * @param ruleName å½“å‰è§„åˆ™åç§°
     * @param ruleStack è§„åˆ™è°ƒç”¨æ ˆ
     * @returns true: ç¡®å®šæ˜¯å·¦é€’å½’, false: ä¸æ˜¯å·¦é€’å½’ï¼ˆä½†ä¸èƒ½ç¡®å®šæ˜¯ä»€ä¹ˆé—®é¢˜ï¼‰
     */
    private isDirectLeftRecursion(ruleName: string, ruleStack: string[]): boolean {
        // æ£€æŸ¥è§„åˆ™æ ˆä¸­æ˜¯å¦æœ‰ä»»ä½•è§„åˆ™å‡ºç°äº† >= 2 æ¬¡
        // è¿™å¯ä»¥æ£€æµ‹ç›´æ¥å·¦é€’å½’å’Œé—´æ¥å·¦é€’å½’

        const ruleCounts = new Map<string, number>()

        for (const rule of ruleStack) {
            ruleCounts.set(rule, (ruleCounts.get(rule) || 0) + 1)
        }

        // å¦‚æœä»»ä½•è§„åˆ™å‡ºç° >= 2 æ¬¡ï¼Œè¯´æ˜æœ‰é€’å½’
        for (const count of ruleCounts.values()) {
            if (count >= 2) {
                return true  // âœ… ç¡®å®šæ˜¯å·¦é€’å½’ï¼ˆç›´æ¥æˆ–é—´æ¥ï¼‰
            }
        }

        // å¦åˆ™ï¼Œä¸æ˜¯å·¦é€’å½’
        // ä½†å¯èƒ½æ˜¯å…¶ä»–é—®é¢˜ï¼šOr åˆ†æ”¯é®è”½ã€è§„åˆ™å®ç°é”™è¯¯ã€è¯­æ³•é”™è¯¯ç­‰
        return false  // âŒ ä¸æ˜¯å·¦é€’å½’ï¼ˆä½†ä¸ç¡®å®šå…·ä½“æ˜¯ä»€ä¹ˆé—®é¢˜ï¼‰
    }

    /**
     * æŠ›å‡ºå¾ªç¯é”™è¯¯ä¿¡æ¯
     *
     * @param ruleName å½“å‰è§„åˆ™åç§°
     */
    private throwLoopError(ruleName: string): never {
        // ğŸ” åˆ†ææ¨¡å¼ï¼šä¸æŠ›å¼‚å¸¸ï¼Œç›´æ¥è¿”å›
        if (this._analysisMode) {
            // æ ‡è®°è§£æå¤±è´¥ï¼Œè®© RuleCollector çŸ¥é“è¿™ä¸ªè§„åˆ™æœ‰é—®é¢˜
            this._parseSuccess = false
            return undefined as never
        }

        // è·å–å½“å‰ token ä¿¡æ¯
        const currentToken = this.curToken

        // è·å– token ä¸Šä¸‹æ–‡ï¼ˆå‰åå„ 2 ä¸ªï¼‰
        const tokenContext: SubhutiMatchToken[] = []
        const contextRange = 2
        for (let i = Math.max(0, this.tokenIndex - contextRange);
             i <= Math.min(this._tokens.length - 1, this.tokenIndex + contextRange);
             i++) {
            if (this._tokens[i]) {
                tokenContext.push(this._tokens[i])
            }
        }

        // è·å–ç¼“å­˜ç»Ÿè®¡
        const cacheStatsReport = this._cache.getStatsReport()

        // ğŸ” åˆ†æå¾ªç¯ç±»å‹ï¼šçœŸæ­£çš„å·¦é€’å½’ vs Or åˆ†æ”¯é®è”½
        const ruleStack = this.getRuleStack()
        const isDirectLeftRecursion = this.isDirectLeftRecursion(ruleName, ruleStack)
        const errorType = isDirectLeftRecursion ? 'left-recursion' : 'or-branch-shadowing'

        // åˆ›å»ºå¾ªç¯é”™è¯¯ï¼ˆå¹³é“ºç»“æ„ï¼‰
        throw this._errorHandler.createError({
            type: errorType,
            expected: '',
            found: currentToken,
            position: currentToken ? {
                tokenIndex: this.tokenIndex,
                charIndex: currentToken.index || 0,
                line: currentToken.rowNum || 0,
                column: currentToken.columnStartNum || 0
            } : {
                tokenIndex: this._tokens.length,
                charIndex: this._tokens[this._tokens.length - 1]?.index || 0,
                line: this._tokens[this._tokens.length - 1]?.rowNum || 0,
                column: this._tokens[this._tokens.length - 1]?.columnEndNum || 0
            },
            ruleStack: [...ruleStack],
            loopRuleName: ruleName,
            loopDetectionSet: Array.from(this.loopDetectionSet),
            loopCstDepth: this.cstStack.length,
            loopCacheStats: {
                hits: cacheStatsReport.hits,
                misses: cacheStatsReport.misses,
                hitRate: cacheStatsReport.hitRate,
                currentSize: cacheStatsReport.currentSize
            },
            loopTokenContext: tokenContext,
            hint: 'æ£€æŸ¥è§„åˆ™å®šä¹‰ï¼Œç¡®ä¿åœ¨é€’å½’å‰æ¶ˆè´¹äº† token'
        })
    }

    /**
     * è§„åˆ™æ‰§è¡Œå…¥å£ï¼ˆç”± @SubhutiRule è£…é¥°å™¨è°ƒç”¨ï¼‰
     * èŒè´£ï¼šå‰ç½®æ£€æŸ¥ â†’ å¾ªç¯æ£€æµ‹ â†’ Packrat ç¼“å­˜ â†’ æ ¸å¿ƒæ‰§è¡Œ â†’ åç½®å¤„ç†
     */
    private executeRuleWrapper(targetFun: Function, ruleName: string, className: string, ...args: any[]): SubhutiCst | undefined {
        if (this.checkRuleIsThisClass(ruleName, className)) {
            return
        }
        const isTopLevel = this.cstStack.length === 0

        if (isTopLevel) {
            this.initTopLevelData()
        }

        if (this.parserFail) {
            return
        }

        const key = `${ruleName}:${this.tokenIndex}`

        // O(1) å¿«é€Ÿæ£€æµ‹æ˜¯å¦é‡å¤ï¼ˆå¾ªç¯æ£€æµ‹ï¼‰
        if (this.loopDetectionSet.has(key)) {
            this.throwLoopError(ruleName)
        }

        // å…¥æ ˆ
        this.loopDetectionSet.add(key)

        try {
            const startTime = this._debugger?.onRuleEnter(ruleName, this.tokenIndex)

            // Packrat Parsing ç¼“å­˜æŸ¥è¯¢
            if (this.enableMemoization) {
                const cached = this._cache.get(ruleName, this.tokenIndex)
                if (cached !== undefined) {
                    this._debugger?.onRuleExit(ruleName, true, startTime)

                    // è§£æè®°å½•æ¨¡å¼ï¼šç¼“å­˜å‘½ä¸­æ—¶ä¹Ÿè¦è®°å½•èŠ‚ç‚¹ï¼Œå¹¶æ›´æ–°æ•´ä¸ªç¥–å…ˆé“¾çš„ endTokenIndex
                    if (this.errorRecoveryMode && cached.endTokenIndex > this.tokenIndex) {
                        // åˆ›å»ºè®°å½•èŠ‚ç‚¹ï¼Œå¤åˆ¶ç¼“å­˜ä¸­çš„ children
                        const recordNode: ParseRecordNode = {
                            name: ruleName,
                            startTokenIndex: this.tokenIndex,
                            endTokenIndex: cached.endTokenIndex,
                            children: cached.recordNode?.children ? [...cached.recordNode.children] : [],
                            token: false
                        }
                        const recordParent = this._parseRecordStack[this._parseRecordStack.length - 1]
                        if (recordParent) {
                            recordParent.children.push(recordNode)
                        }
                        // æ›´æ–°æ•´ä¸ªç¥–å…ˆé“¾çš„ endTokenIndexï¼ˆç±»ä¼¼ consume çš„è¡Œä¸ºï¼‰
                        for (let i = this._parseRecordStack.length - 1; i >= 0; i--) {
                            const ancestor = this._parseRecordStack[i]
                            if (cached.endTokenIndex > ancestor.endTokenIndex) {
                                ancestor.endTokenIndex = cached.endTokenIndex
                            }
                        }
                    }

                    const cst = this.applyCachedResult(cached)
                    if (!cst.children?.length) {
                        cst.children = undefined
                    }
                    return cst
                }
            }

            // æ ¸å¿ƒæ‰§è¡Œ
            const startTokenIndex = this.tokenIndex

            // è§£æè®°å½•æ ‘ï¼šåˆ›å»ºèŠ‚ç‚¹å¹¶å…¥æ ˆï¼ˆåœ¨ executeRuleCore ä¹‹å‰ï¼‰
            let recordNode: ParseRecordNode | null = null
            if (this.errorRecoveryMode) {
                recordNode = {
                    name: ruleName,
                    children: [],
                    startTokenIndex: this.tokenIndex,
                    endTokenIndex: this.tokenIndex
                }
                this._parseRecordStack.push(recordNode)
            }

            const cst = this.executeRuleCore(ruleName, targetFun, ...args)

            // è§£æè®°å½•æ ‘ï¼šå‡ºæ ˆï¼Œåªæœ‰æ¶ˆè´¹äº† token æ‰æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
            if (this.errorRecoveryMode && recordNode) {
                this._parseRecordStack.pop()
                if (recordNode.endTokenIndex > recordNode.startTokenIndex) {
                    const recordParent = this._parseRecordStack[this._parseRecordStack.length - 1]
                    if (recordParent) {
                        recordParent.children.push(recordNode)
                    }
                }
            }

            // ç¼“å­˜å­˜å‚¨
            // æ³¨æ„ï¼šä½¿ç”¨ recordNode.endTokenIndexï¼ˆå¦‚æœæœ‰ï¼‰ï¼Œå› ä¸º this.tokenIndex å¯èƒ½å·²è¢« Or å›æ»š
            if (this.enableMemoization) {
                const endTokenIndex = recordNode ? Math.max(recordNode.endTokenIndex, this.tokenIndex) : this.tokenIndex
                this._cache.set(ruleName, startTokenIndex, {
                    endTokenIndex: endTokenIndex,
                    cst: cst,
                    parseSuccess: this._parseSuccess,
                    recordNode: recordNode  // ç›´æ¥å­˜å‚¨ recordNode
                })
            }

            this.onRuleExitDebugHandler(ruleName, cst, isTopLevel, startTime)

            // é¡¶å±‚è§„åˆ™ï¼šæ£€æŸ¥æ˜¯å¦æ‰€æœ‰ token éƒ½è¢«æ¶ˆè´¹
            // å¦‚æœæˆåŠŸä½†è¿˜æœ‰å‰©ä½™ tokenï¼Œè¯´æ˜è§£æå™¨é€»è¾‘æœ‰é—®é¢˜ï¼Œç›´æ¥æŠ›é”™
            if (isTopLevel && this._parseSuccess && this.tokenIndex < this._tokens.length) {
                const remainingToken = this.curToken!
                throw new Error(
                    `Parser internal error: parsing succeeded but ${this._tokens.length - this.tokenIndex} tokens remain unconsumed. ` +
                    `Next token: "${remainingToken.tokenValue}" (${remainingToken.tokenName}) at line ${remainingToken.rowNum}, column ${remainingToken.columnStartNum}`
                )
            }

            // é¡¶å±‚è§„åˆ™å¤±è´¥æ—¶çš„é”™è¯¯å¤„ç†
            if (isTopLevel && this.parserFail) {
                this.handleTopLevelError(ruleName, startTokenIndex)
            }

            if (!cst.children?.length) {
                cst.children = undefined
            }
            return cst
        } finally {
            // å‡ºæ ˆï¼ˆæ— è®ºæˆåŠŸã€returnã€å¼‚å¸¸éƒ½ä¼šæ‰§è¡Œï¼‰
            this.loopDetectionSet.delete(key)
        }
    }

    private initTopLevelData() {
        // ã€é¡¶å±‚è§„åˆ™å¼€å§‹ã€‘é‡ç½®è§£æå™¨çŠ¶æ€
        // é‡ç½® Parser çš„å†…éƒ¨çŠ¶æ€
        this._parseSuccess = true
        this.cstStack.length = 0
        this.loopDetectionSet.clear()
        this.tokenIndex = 0  // âœ… é‡ç½® tokenIndex

        // ============================================
        // ã€æ–°å¢ã€‘é‡ç½®è°ƒè¯•å™¨çš„ç¼“å­˜å’Œç»Ÿè®¡
        // ============================================
        // è¿™æ ·æ¯æ¬¡æ–°çš„é¡¶å±‚è§£æéƒ½æœ‰å¹²å‡€çš„ç¯å¢ƒ
        this._debugger?.resetForNewParse?.(this._tokens)
    }

    private checkRuleIsThisClass(ruleName: string, className: string): boolean {
        if (this.hasOwnProperty(ruleName)) {
            if (className !== this.className) {
                return true
            }
        }
    }

    private onRuleExitDebugHandler(
        ruleName: string,
        cst: SubhutiCst | undefined,
        isTopLevel: boolean,
        startTime?: number
    ): void {
        if (cst && !cst.children?.length) {
            cst.children = undefined
        }

        if (!isTopLevel) {
            this._debugger?.onRuleExit(ruleName, false, startTime)
        } else {
            // é¡¶å±‚è§„åˆ™å®Œæˆï¼Œè¾“å‡ºè°ƒè¯•ä¿¡æ¯
            if (this._debugger) {
                if ('setCst' in this._debugger) {
                    (this._debugger as any).setCst(cst)
                }
                (this._debugger as any)?.autoOutput?.()
            }
        }
    }

    /**
     * æ‰§è¡Œè§„åˆ™å‡½æ•°æ ¸å¿ƒé€»è¾‘
     * èŒè´£ï¼šåˆ›å»º CST â†’ æ‰§è¡Œè§„åˆ™ â†’ æˆåŠŸåˆ™æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
     */
    private executeRuleCore(ruleName: string, targetFun: Function, ...args: any[]): SubhutiCst {
        const cst = new SubhutiCst()
        cst.name = ruleName
        cst.children = []

        this.cstStack.push(cst)

        // æ‰§è¡Œè§„åˆ™å‡½æ•°
        targetFun.apply(this, args)

        this.cstStack.pop()

        // æˆåŠŸæ—¶æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹å¹¶è®¾ç½®ä½ç½®
        if (this._parseSuccess) {
            const parentCst = this.cstStack[this.cstStack.length - 1]
            if (parentCst) {
                parentCst.children.push(cst)
            }
            this.setLocation(cst)
        }

        return cst
    }

    private setLocation(cst: SubhutiCst): void {
        if (cst.children && cst.children[0]?.loc) {
            const lastChild = cst.children[cst.children.length - 1]
            cst.loc = {
                type: cst.name,
                start: cst.children[0].loc.start,
                end: lastChild?.loc?.end || cst.children[0].loc.end
            }
        }
    }

    /**
     * Or è§„åˆ™ - é¡ºåºé€‰æ‹©ï¼ˆPEG é£æ ¼ï¼‰
     *
     * æ ¸å¿ƒé€»è¾‘ï¼š
     * - ä¾æ¬¡å°è¯•æ¯ä¸ªåˆ†æ”¯ï¼Œç¬¬ä¸€ä¸ªæˆåŠŸçš„åˆ†æ”¯ç”Ÿæ•ˆ
     * - æ‰€æœ‰åˆ†æ”¯éƒ½å¤±è´¥åˆ™æ•´ä½“å¤±è´¥
     *
     * ä¼˜åŒ–ï¼šåªæœ‰æ¶ˆè´¹äº† token æ‰éœ€è¦å›æº¯ï¼ˆæ²¡æ¶ˆè´¹ = çŠ¶æ€æ²¡å˜ï¼‰
     */
    Or(alternatives: SubhutiParserOr[]): void {
        if (this.parserFail) {
            return
        }

        const savedState = this.saveState()
        const startTokenIndex = this.tokenIndex
        const totalCount = alternatives.length
        const parentRuleName = this.curCst?.name || 'Unknown'

        // è¿›å…¥ Orï¼ˆæ•´ä¸ª Or è°ƒç”¨å¼€å§‹ï¼‰
        this._debugger?.onOrEnter?.(parentRuleName, this.tokenIndex)

        for (let i = 0; i < totalCount; i++) {
            const alt = alternatives[i]
            const isLast = i === totalCount - 1

            // è¿›å…¥ Or åˆ†æ”¯
            this._debugger?.onOrBranch?.(i, totalCount, parentRuleName)

            alt.alt()

            // é€€å‡º Or åˆ†æ”¯ï¼ˆæ— è®ºæˆåŠŸè¿˜æ˜¯å¤±è´¥ï¼‰
            this._debugger?.onOrBranchExit?.(parentRuleName, i)

            if (this._parseSuccess) {
                // é€€å‡º Orï¼ˆæ•´ä¸ª Or è°ƒç”¨æˆåŠŸç»“æŸï¼‰
                this._debugger?.onOrExit?.(parentRuleName)
                return
            }

            // å‰ N-1 ä¸ªåˆ†æ”¯ï¼šå¤±è´¥åå›æº¯å¹¶é‡ç½®çŠ¶æ€ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª
            if (!isLast) {
                this.recordPartialMatchAndRestore(savedState, startTokenIndex)
                this._parseSuccess = true
            }
            // æœ€åä¸€ä¸ªåˆ†æ”¯ï¼šå¤±è´¥åä¸å›æº¯ï¼Œä¿æŒå¤±è´¥çŠ¶æ€
        }

        // é€€å‡º Orï¼ˆæ•´ä¸ª Or è°ƒç”¨å¤±è´¥ç»“æŸï¼‰
        this._debugger?.onOrExit?.(parentRuleName)
    }

    /**
     * Many è§„åˆ™ - 0æ¬¡æˆ–å¤šæ¬¡ï¼ˆEBNF { ... }ï¼‰
     *
     * å¾ªç¯æ‰§è¡Œç›´åˆ°å¤±è´¥æˆ–æ²¡æ¶ˆè´¹ token
     */
    Many(fn: RuleFunction): void {
        while (this.tryAndRestore(fn)) {
            // ç»§ç»­å¾ªç¯
        }
    }

    /**
     * å¸¦å®¹é”™çš„ Many è§„åˆ™ï¼ˆä½¿ç”¨è§£æè®°å½•æ ‘ï¼‰
     * - å½“å…¨å±€ errorRecoveryMode å¼€å¯æ—¶ï¼Œè§£æå¤±è´¥ä¼šå°è¯•æ¢å¤å¹¶ç»§ç»­
     * - ä½¿ç”¨è§£æè®°å½•æ ‘è®°å½•æ‰€æœ‰è§£æå°è¯•ï¼Œåªå¢ä¸åˆ 
     * - å¤±è´¥æ—¶ä»è§£æè®°å½•æ ‘æå–æœ€ä¼˜è·¯å¾„æ¢å¤ CST
     * @param fn è¦æ‰§è¡Œçš„è§„åˆ™å‡½æ•°
     */
    ManyWithRecovery(fn: RuleFunction): void {
        if (!this.errorRecoveryMode) {
            throw new Error('éå®¹é”™æ¨¡å¼ä¸åº”è¯¥è¿›å…¥ ManyWithRecovery')
        }

        // æ¸…ç†è®°å½•
        this._unparsedTokens.length = 0

        while (!this.parserFailOrIsEof) {
            const startTokenIndex = this.tokenIndex

            // å¯ç”¨è§£æè®°å½•ï¼Œä¸ºæœ¬æ¬¡è¿­ä»£åˆ›å»ºæ ¹èŠ‚ç‚¹
            this._parseRecordRoot = {
                name: '__ParseRecordRoot__',
                children: [],
                startTokenIndex: startTokenIndex,
                endTokenIndex: startTokenIndex
            }
            this._parseRecordStack = [this._parseRecordRoot]

            const success = this.tryAndRestore(fn)

            if (success) {
                // æˆåŠŸï¼Œæ¸…ç†è§£æè®°å½•æ ‘ï¼Œç»§ç»­ä¸‹ä¸€ä¸ª
                this._parseRecordRoot = null
                this._parseRecordStack = []
                continue
            }

            // è§£æå¤±è´¥ï¼Œå°è¯•ä»è§£æè®°å½•æ ‘æ¢å¤
            const syncIndex = this.findNextSyncPoint(startTokenIndex + 1)
            const recoveredCST = this.recoverFromParseRecord(this._parseRecordRoot!, syncIndex)

            if (recoveredCST && recoveredCST.children && recoveredCST.children.length > 0) {
                // æ¢å¤æˆåŠŸï¼Œå°† CST æ·»åŠ åˆ°å½“å‰èŠ‚ç‚¹
                const currentCst = this.curCst
                if (currentCst) {
                    currentCst.children.push(...recoveredCST.children)
                }
                // ä»æ¢å¤çš„ä½ç½®ç»§ç»­
                this.tokenIndex = this.getParseRecordMaxEndIndex(this._parseRecordRoot!, syncIndex)
            } else {
                // æ²¡æœ‰å¯æ¢å¤çš„å†…å®¹ï¼Œè®°å½•å½“å‰ token ä¸ºæœªè§£æï¼Œè·³è¿‡ç»§ç»­
                if (this.tokenIndex < this._tokens.length) {
                    this._unparsedTokens.push(this._tokens[this.tokenIndex])
                }
                this.tokenIndex++
            }

            // æ¸…ç†è§£æè®°å½•æ ‘
            this._parseRecordRoot = null
            this._parseRecordStack = []
            this._parseSuccess = true
        }

        // å‡ºå£ï¼šå¦‚æœæœ‰æœªè§£æçš„ tokensï¼Œæ ‡è®°è§£æå¤±è´¥
        if (this._unparsedTokens.length > 0) {
            this._parseSuccess = false
        }
    }

    /**
     * ä»è§£æè®°å½•æ ‘æ¢å¤ CST
     * æ‰¾åˆ° endTokenIndex <= maxIndex çš„æœ€æ·±è·¯å¾„ï¼Œè½¬æ¢ä¸º CST
     */
    private recoverFromParseRecord(root: ParseRecordNode, maxIndex: number): SubhutiCst | null {
        if (!root || root.children.length === 0) {
            return null
        }

        const cst = new SubhutiCst()
        cst.name = root.name
        cst.children = this.parseRecordChildrenToCST(root.children, maxIndex)

        if (!cst.children || cst.children.length === 0) {
            return null
        }

        return cst
    }

    /**
     * å°†è§£æè®°å½•æ ‘å­èŠ‚ç‚¹è½¬æ¢ä¸º CST å­èŠ‚ç‚¹
     *
     * é€‰æ‹©ç­–ç•¥ï¼š
     * 1. æŒ‰ startTokenIndex åˆ†ç»„ï¼ˆåŒä¸€ä½ç½®å¼€å§‹çš„æ˜¯ Or çš„ä¸åŒåˆ†æ”¯ï¼‰
     * 2. å¯¹äºæ¯ç»„ï¼Œé€‰æ‹© endTokenIndex <= maxIndex ä¸”æœ€å¤§çš„
     * 3. å¦‚æœæœ‰å¤šä¸ªç›¸åŒæ·±åº¦çš„ï¼Œé€‰æ‹©æœ€åä¸€ä¸ª
     */
    private parseRecordChildrenToCST(nodes: ParseRecordNode[], maxIndex: number): SubhutiCst[] {
        // æŒ‰ startTokenIndex åˆ†ç»„
        const groups = new Map<number, ParseRecordNode[]>()
        for (const node of nodes) {
            // è·³è¿‡è¶…è¿‡åŒæ­¥ç‚¹çš„èŠ‚ç‚¹
            if (node.endTokenIndex > maxIndex) {
                continue
            }
            const key = node.startTokenIndex
            if (!groups.has(key)) {
                groups.set(key, [])
            }
            groups.get(key)!.push(node)
        }

        // å¯¹æ¯ç»„é€‰æ‹©æœ€ä¼˜èŠ‚ç‚¹
        const selectedNodes: ParseRecordNode[] = []
        for (const [startIdx, group] of groups) {
            // é€‰æ‹© endTokenIndex æœ€å¤§çš„ï¼Œå¦‚æœç›¸åŒåˆ™é€‰æœ€åä¸€ä¸ªï¼ˆå…œåº•åˆ†æ”¯ï¼Œæ›´é€šç”¨ï¼‰
            let best: ParseRecordNode | null = null
            for (const node of group) {
                if (!best || node.endTokenIndex >= best.endTokenIndex) {
                    best = node
                }
            }
            if (best) {
                selectedNodes.push(best)
            }
        }

        // æŒ‰ startTokenIndex æ’åºï¼Œä¿è¯é¡ºåºæ­£ç¡®
        selectedNodes.sort((a, b) => a.startTokenIndex - b.startTokenIndex)

        // è½¬æ¢ä¸º CST
        return selectedNodes.map(node => this.parseRecordNodeToCST(node, maxIndex))
    }

    /**
     * å°†å•ä¸ªè§£æè®°å½•èŠ‚ç‚¹è½¬æ¢ä¸º CST èŠ‚ç‚¹
     */
    private parseRecordNodeToCST(node: ParseRecordNode, maxIndex: number): SubhutiCst {
        const cst = new SubhutiCst()
        cst.name = node.name

        // å¦‚æœæ˜¯ token èŠ‚ç‚¹
        if (node.token) {
            cst.value = node.value
            cst.loc = {
                type: node.token.tokenName,
                value: node.token.tokenValue,
                start: {
                    index: node.token.index || 0,
                    line: node.token.rowNum || 0,
                    column: node.token.columnStartNum || 0
                },
                end: {
                    index: (node.token.index || 0) + node.token.tokenValue.length,
                    line: node.token.rowNum || 0,
                    column: node.token.columnEndNum || 0
                }
            }
        }

        // é€’å½’è½¬æ¢å­èŠ‚ç‚¹
        if (node.children.length > 0) {
            cst.children = this.parseRecordChildrenToCST(node.children, maxIndex)
            if (cst.children.length === 0) {
                cst.children = undefined
            } else {
                // è®¾ç½®ä½ç½®ä¿¡æ¯
                this.setLocation(cst)
            }
        }

        return cst
    }

    /**
     * è·å–è§£æè®°å½•æ ‘ä¸­ <= maxIndex çš„æœ€å¤§ endTokenIndex
     */
    private getParseRecordMaxEndIndex(root: ParseRecordNode, maxIndex: number): number {
        let maxEnd = root.endTokenIndex <= maxIndex ? root.endTokenIndex : 0

        for (const child of root.children) {
            const childMax = this.getParseRecordMaxEndIndex(child, maxIndex)
            if (childMax > maxEnd) {
                maxEnd = childMax
            }
        }

        return maxEnd
    }

    /**
     * æ‰¾åˆ°ä¸‹ä¸€ä¸ªåŒæ­¥ç‚¹ï¼ˆè¯­å¥å¼€å§‹ tokenï¼‰
     * @param fromIndex ä»å“ªä¸ªç´¢å¼•å¼€å§‹æŸ¥æ‰¾
     * @returns åŒæ­¥ç‚¹çš„ token ç´¢å¼•ï¼Œå¦‚æœæ²¡æ‰¾åˆ°è¿”å› token åˆ—è¡¨æœ«å°¾
     */
    protected findNextSyncPoint(fromIndex: number): number {
        for (let i = fromIndex; i < this._tokens.length; i++) {
            const token = this._tokens[i]
            if (this._syncTokens.has(token.tokenName)) {
                return i
            }
        }
        return this._tokens.length  // æ²¡æ‰¾åˆ°ï¼Œè¿”å›æœ«å°¾
    }

    /**
     * åˆ›å»º ErrorNodeï¼ŒåŒ…å«æŒ‡å®šèŒƒå›´å†…çš„ token
     * @param startIndex èµ·å§‹ token ç´¢å¼•ï¼ˆåŒ…å«ï¼‰
     * @param endIndex ç»“æŸ token ç´¢å¼•ï¼ˆä¸åŒ…å«ï¼‰
     * @returns ErrorNode CST èŠ‚ç‚¹
     */
    protected createErrorNode(startIndex: number, endIndex: number): SubhutiCst {
        const errorNode = new SubhutiCst()
        errorNode.name = 'ErrorNode'
        errorNode.children = []

        // å°†æ¯ä¸ª token è½¬ä¸ºå¶å­èŠ‚ç‚¹
        for (let i = startIndex; i < endIndex; i++) {
            const token = this._tokens[i]
            const tokenNode = new SubhutiCst()
            tokenNode.name = token.tokenName
            tokenNode.value = token.tokenValue
            tokenNode.loc = {
                type: token.tokenName,
                value: token.tokenValue,
                start: {
                    index: token.index,
                    line: token.rowNum,
                    column: token.columnStartNum
                },
                end: {
                    index: token.index + (token.tokenValue?.length || 0),
                    line: token.rowNum,
                    column: token.columnEndNum
                }
            }
            errorNode.children.push(tokenNode)
        }

        // è®¾ç½® ErrorNode çš„ä½ç½®ä¿¡æ¯
        if (errorNode.children.length > 0) {
            const first = errorNode.children[0]
            const last = errorNode.children[errorNode.children.length - 1]
            errorNode.loc = {
                type: 'ErrorNode',
                start: first.loc.start,
                end: last.loc.end
            }
        }

        return errorNode
    }

    /**
     * Option è§„åˆ™ - 0æ¬¡æˆ–1æ¬¡ï¼ˆEBNF [ ... ]ï¼‰
     *
     * å°è¯•æ‰§è¡Œä¸€æ¬¡ï¼Œå¤±è´¥åˆ™å›æº¯ï¼Œä¸å½±å“æ•´ä½“è§£æçŠ¶æ€
     */
    Option(fn: RuleFunction): void {
        this.tryAndRestore(fn)
    }

    /**
     * AtLeastOne è§„åˆ™ - 1æ¬¡æˆ–å¤šæ¬¡
     *
     * ç¬¬ä¸€æ¬¡å¿…é¡»æˆåŠŸï¼Œåç»­å¾ªç¯æ‰§è¡Œç›´åˆ°å¤±è´¥
     */
    AtLeastOne(fn: RuleFunction): void {
        if (this.parserFail) {
            return
        }

        fn()

        while (this.tryAndRestore(fn)) {
            // ç»§ç»­å¾ªç¯
        }
    }

    /**
     * é¡¶å±‚è§„åˆ™å¤±è´¥æ—¶çš„é”™è¯¯å¤„ç†
     *
     * @param ruleName è§„åˆ™å
     * @param startTokenIndex è§„åˆ™å¼€å§‹æ—¶çš„ tokenIndex
     */
    private handleTopLevelError(ruleName: string, startTokenIndex: number): void {
        // åˆ†ææ¨¡å¼ï¼šä¸æŠ›é”™ï¼Œç”¨äºè¯­æ³•éªŒè¯
        if (this._analysisMode) {
            return
        }

        // æ­£å¸¸æ¨¡å¼ï¼šæŠ›å‡ºè§£æé”™è¯¯
        const noTokenConsumed = this.tokenIndex === startTokenIndex
        const found = this.curToken

        throw this._errorHandler.createError({
            type: 'parsing',
            expected: noTokenConsumed ? 'valid syntax' : 'EOF (end of file)',
            found: found,
            position: {
                tokenIndex: this.tokenIndex,
                charIndex: found?.index ?? this._tokens[this._tokens.length - 1]?.index ?? 0,
                line: found?.rowNum ?? 1,
                column: found?.columnStartNum ?? 1
            },
            ruleStack: this.getRuleStack().length > 0 ? this.getRuleStack() : [ruleName]
        })
    }

    get parserFailOrIsEof() {
        return this.parserFail || this.isEof
    }

    /**
     * æ¶ˆè´¹ tokenï¼ˆæ™ºèƒ½é”™è¯¯ç®¡ç†ï¼‰
     * - å¤±è´¥æ—¶è¿”å› undefinedï¼Œä¸æŠ›å¼‚å¸¸
     */
    consume(tokenName: string): SubhutiCst | undefined {
        if (this.parserFail) {
            return
        }

        if (this.isEof) {
            this._parseSuccess = false
            return
        }

        // å·²ç»æ£€æŸ¥äº† EOFï¼Œtoken ä¸€å®šå­˜åœ¨
        const token = this.curToken!

        if (token.tokenName !== tokenName) {
            this._parseSuccess = false

            this._debugger?.onTokenConsume(
                this.tokenIndex,
                token.tokenValue,
                token.tokenName,
                tokenName,
                false
            )

            return
        }

        this._debugger?.onTokenConsume(
            this.tokenIndex,
            token.tokenValue,
            token.tokenName,
            tokenName,
            true
        )

        this.generateCstByToken(token)
        this.tokenIndex++
    }

    private generateCstByToken(token: SubhutiMatchToken): SubhutiCst {
        const cst = new SubhutiCst()
        cst.name = token.tokenName
        cst.value = token.tokenValue
        cst.loc = {
            type: token.tokenName,
            value: token.tokenValue,
            start: {
                index: token.index || 0,
                line: token.rowNum || 0,
                column: token.columnStartNum || 0
            },
            end: {
                index: (token.index || 0) + token.tokenValue.length,
                line: token.rowNum || 0,
                column: token.columnEndNum || 0
            }
        }

        // æ·»åŠ åˆ°å½“å‰ CST
        const currentCst = this.curCst
        if (currentCst) {
            currentCst.children.push(cst)
        }

        // è§£æè®°å½•æ ‘ï¼šè®°å½• token å¹¶æ›´æ–°ç¥–å…ˆçš„ endTokenIndex
        if (this.errorRecoveryMode) {
            const newEndIndex = this.tokenIndex + 1  // consume å tokenIndex ä¼š +1
            const tokenNode: ParseRecordNode = {
                name: token.tokenName,
                children: [],
                startTokenIndex: this.tokenIndex,
                endTokenIndex: newEndIndex,
                token: token,
                value: token.tokenValue
            }
            const recordCurrent = this._parseRecordStack[this._parseRecordStack.length - 1]
            if (recordCurrent) {
                recordCurrent.children.push(tokenNode)
            }
            // æ›´æ–°æ‰€æœ‰ç¥–å…ˆçš„ endTokenIndex
            for (const ancestor of this._parseRecordStack) {
                ancestor.endTokenIndex = newEndIndex
            }
        }

        return cst
    }

    // å›æº¯æœºåˆ¶
    private saveState(): SubhutiBackData {
        const currentCst = this.curCst
        return {
            tokenIndex: this.tokenIndex,
            curCstChildrenLength: currentCst?.children?.length || 0
        }
    }

    private restoreState(backData: SubhutiBackData): void {
        const fromIndex = this.tokenIndex
        const toIndex = backData.tokenIndex

        if (fromIndex !== toIndex) {
            this._debugger?.onBacktrack?.(fromIndex, toIndex)
        }

        this.tokenIndex = backData.tokenIndex
        const currentCst = this.curCst
        if (currentCst) {
            currentCst.children.length = backData.curCstChildrenLength
        }
    }

    /**
     * ã€å®¹é”™æ¨¡å¼ã€‘è®°å½•éƒ¨åˆ†åŒ¹é…å¹¶å›æº¯
     * - å…ˆè®°å½•è¢«å›æº¯åˆ é™¤ä½†æ¶ˆè´¹äº† token çš„ CST ç‰‡æ®µ
     * - å†æ‰§è¡Œå›æº¯
     *
     * @param savedState ä¿å­˜çš„çŠ¶æ€
     * @param startTokenIndex èµ·å§‹ token ä½ç½®
     */
    private recordPartialMatchAndRestore(savedState: SubhutiBackData, startTokenIndex: number): void {
        // æ³¨æ„ï¼šè§£æè®°å½•æ ‘æ–¹æ¡ˆä¸­ï¼Œéƒ¨åˆ†åŒ¹é…ç”± _parseRecordRoot è®°å½•ï¼Œè¿™é‡Œåªéœ€è¦å›æº¯ CST
        // è§£æè®°å½•æ ‘æ˜¯åªå¢ä¸åˆ çš„ï¼Œä¸å— restoreState å½±å“
        this.restoreState(savedState)
    }

    get isEof() {
        return this.tokenIndex === this._tokens.length
    }

    /**
     * å°è¯•æ‰§è¡Œå‡½æ•°ï¼Œå¤±è´¥æ—¶è‡ªåŠ¨å›æº¯å¹¶é‡ç½®çŠ¶æ€
     *
     * @param fn è¦æ‰§è¡Œçš„å‡½æ•°
     * @returns true: æˆåŠŸä¸”æ¶ˆè´¹äº† tokenï¼Œfalse: å¤±è´¥æˆ–æ²¡æ¶ˆè´¹ token
     */
    private tryAndRestore(fn: () => void): boolean {
        if (this.parserFailOrIsEof) {
            return false
        }
        const savedState = this.saveState()
        const startTokenIndex = this.tokenIndex

        fn()

        if (this.parserFail) {
            // è®°å½•éƒ¨åˆ†åŒ¹é…å¹¶å›æº¯
            this.recordPartialMatchAndRestore(savedState, startTokenIndex)
            this._parseSuccess = true
            return false
        }

        // æˆåŠŸä½†æ²¡æ¶ˆè´¹ token â†’ è¿”å› falseï¼ˆé˜²æ­¢æ— é™å¾ªç¯ï¼‰
        return this.tokenIndex !== startTokenIndex
    }

    /**
     * åº”ç”¨ç¼“å­˜ç»“æœï¼ˆæ¢å¤çŠ¶æ€ï¼‰
     */
    private applyCachedResult(cached: SubhutiPackratCacheResult): SubhutiCst {
        this.tokenIndex = cached.endTokenIndex
        this._parseSuccess = cached.parseSuccess

        // æˆåŠŸæ—¶æ·»åŠ åˆ°çˆ¶èŠ‚ç‚¹
        if (cached.parseSuccess) {
            const parentCst = this.cstStack[this.cstStack.length - 1]
            if (parentCst) {
                parentCst.children.push(cached.cst)
            }
        }

        return cached.cst
    }

    // ============================================
    // Error Helper Methods
    // ============================================

    /**
     * è·å– token ä¸Šä¸‹æ–‡ï¼ˆå‰åå„ N ä¸ª tokenï¼‰
     *
     * @param tokenIndex - å½“å‰ token ç´¢å¼•
     * @param contextSize - ä¸Šä¸‹æ–‡å¤§å°ï¼ˆé»˜è®¤ 2ï¼‰
     * @returns token ä¸Šä¸‹æ–‡æ•°ç»„
     */
    private getTokenContext(tokenIndex: number, contextSize: number = 2): SubhutiMatchToken[] {
        const start = Math.max(0, tokenIndex - contextSize)
        const end = Math.min(this._tokens.length, tokenIndex + contextSize + 1)
        return this._tokens.slice(start, end)
    }

    /**
     * ç”Ÿæˆå½“å‰è§„åˆ™è·¯å¾„çš„å­—ç¬¦ä¸²ï¼ˆç”¨äºé”™è¯¯ä¿¡æ¯ï¼‰
     *
     * @returns æ ¼å¼åŒ–åçš„è§„åˆ™è·¯å¾„å­—ç¬¦ä¸²æ•°ç»„
     */
    private formatCurrentRulePath(): string[] {
        if (!this._debugger) {
            // å¦‚æœæ²¡æœ‰è°ƒè¯•å™¨ï¼Œä½¿ç”¨ç®€å•æ ¼å¼
            return this.formatSimpleRulePath()
        }

        // ä½¿ç”¨è°ƒè¯•å™¨çš„æ ¼å¼åŒ–æ–¹æ³•
        const ruleStack = this._debugger.ruleStack
        if (!ruleStack || ruleStack.length === 0) {
            return ['  (empty)']
        }

        return SubhutiDebugRuleTracePrint.formatPendingOutputs_NonCache_Impl(ruleStack)
    }

    /**
     * ç®€å•æ ¼å¼åŒ–è§„åˆ™è·¯å¾„ï¼ˆå½“æ²¡æœ‰è°ƒè¯•å™¨æ—¶ï¼‰
     */
    private formatSimpleRulePath(): string[] {
        const ruleStack = this.getRuleStack()
        if (ruleStack.length === 0) {
            return ['  (empty)']
        }

        const lines: string[] = []
        for (let i = 0; i < ruleStack.length; i++) {
            const rule = ruleStack[i]
            const isLast = i === ruleStack.length - 1
            const indent = '  '.repeat(i)
            const connector = i === 0 ? '' : 'â””â”€ '
            const marker = isLast ? ' â† å½“å‰ä½ç½®' : ''

            lines.push(`  ${indent}${connector}${rule}${marker}`)
        }

        return lines
    }

    /**
     * åˆ›å»ºæ— é™å¾ªç¯é”™è¯¯
     *
     * @param ruleName - è§„åˆ™åç§°
     * @param hint - ä¿®å¤æç¤º
     * @returns ParsingError å®ä¾‹ï¼ˆåˆ†ææ¨¡å¼ä¸‹è¿”å› nullï¼‰
     */
    private createInfiniteLoopError(ruleName: string, hint: string): ParsingError {
        // ğŸ” åˆ†ææ¨¡å¼ï¼šä¸åˆ›å»ºé”™è¯¯ï¼Œæ ‡è®°å¤±è´¥å¹¶è¿”å› null
        if (this._analysisMode) {
            this._parseSuccess = false
            return null as any  // åˆ†ææ¨¡å¼ä¸‹ä¸ä¼šçœŸæ­£ä½¿ç”¨è¿™ä¸ªè¿”å›å€¼
        }

        // ç”Ÿæˆè§„åˆ™è·¯å¾„
        const rulePathLines = this.formatCurrentRulePath()
        const rulePath = rulePathLines.join('\n')

        // ğŸ” æ£€æµ‹æ˜¯å¦æ˜¯å·¦é€’å½’ï¼ˆå‡†ç¡®åˆ¤æ–­ï¼‰
        const ruleStack = this.getRuleStack()
        const isLeftRecursion = this.isDirectLeftRecursion(ruleName, ruleStack)

        // âœ… åªæœ‰ç¡®å®šæ˜¯å·¦é€’å½’æ—¶æ‰ä½¿ç”¨ 'left-recursion' ç±»å‹
        // âŒ ä¸ç¡®å®šçš„æƒ…å†µä½¿ç”¨ 'infinite-loop'ï¼Œä¸æ–­è¨€æ˜¯ Or é®è”½
        const errorType = isLeftRecursion ? 'left-recursion' : 'infinite-loop'

        return this._errorHandler.createError({
            type: errorType,
            expected: '',
            found: this.curToken,
            position: this.curToken ? {
                tokenIndex: this.tokenIndex,
                charIndex: this.curToken.index || 0,
                line: this.curToken.rowNum || 0,
                column: this.curToken.columnStartNum || 0
            } : {
                tokenIndex: this._tokens.length,
                charIndex: this._tokens[this._tokens.length - 1]?.index || 0,
                line: this._tokens[this._tokens.length - 1]?.rowNum || 0,
                column: this._tokens[this._tokens.length - 1]?.columnEndNum || 0
            },
            ruleStack: [...ruleStack],
            loopRuleName: ruleName,
            loopDetectionSet: [],
            loopCstDepth: this.cstStack.length,
            loopTokenContext: this.getTokenContext(this.tokenIndex, 2),
            hint: hint,
            rulePath: rulePath  // ğŸ†• æ·»åŠ è§„åˆ™è·¯å¾„
        })
    }
}

