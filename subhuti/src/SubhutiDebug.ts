/**
 * Subhuti Debug - è°ƒè¯•å·¥å…·é›†
 * 
 * åŒ…å«ï¼š
 * - SubhutiDebugger: è°ƒè¯•å™¨æ¥å£
 * - SubhutiTraceDebugger: è½¨è¿¹è°ƒè¯•å™¨
 * - SubhutiParserDebugger: è£…é¥°å™¨è°ƒè¯•å™¨
 * - SubhutiVisualizer: å¯è§†åŒ–å™¨
 * 
 * @version 2.0.0 - æ–‡ä»¶åˆå¹¶é‡æ„
 * @date 2025-11-04
 */

import SubhutiParser from "./SubhutiParser.ts"
import type { SubhutiParserOr, RuleFunction } from "./SubhutiParser.ts"
import type { SubhutiMatchToken } from "./SubhutiTypes.ts"
import type SubhutiCst from "./SubhutiTypes.ts"

// ============================================
// [1] SubhutiDebugger - è°ƒè¯•å™¨æ¥å£
// ============================================

/**
 * Subhuti Debugger æ¥å£ï¼ˆv2.0ï¼‰
 * 
 * Parser é€šè¿‡æ­¤æ¥å£é€šçŸ¥è°ƒè¯•å™¨è§£æè¿‡ç¨‹ä¸­çš„äº‹ä»¶
 */
export interface SubhutiDebugger {
    /**
     * è§„åˆ™è¿›å…¥äº‹ä»¶
     */
    onRuleEnter(ruleName: string, tokenIndex: number): unknown
    
    /**
     * è§„åˆ™é€€å‡ºäº‹ä»¶
     */
    onRuleExit(
        ruleName: string, 
        tokenIndex: number, 
        cacheHit: boolean,
        context?: unknown
    ): void
    
    /**
     * Token æ¶ˆè´¹äº‹ä»¶
     */
    onTokenConsume(
        tokenIndex: number,
        tokenValue: string,
        tokenName: string,
        success: boolean
    ): void
    
    /**
     * è·å–æ ¼å¼åŒ–çš„æ‰§è¡Œè½¨è¿¹
     */
    getTrace(): string
    
    /**
     * æ¸…ç©ºè®°å½•
     */
    clear(): void
}

// ============================================
// [2] SubhutiTraceDebugger - è½¨è¿¹è°ƒè¯•å™¨
// ============================================

/**
 * è½¨è¿¹æ¡ç›®ç±»å‹
 */
type TraceEntryType = 'rule-enter' | 'rule-exit' | 'token-consume'

/**
 * è½¨è¿¹æ¡ç›®åŸºç¡€æ¥å£
 */
interface TraceEntryBase {
    type: TraceEntryType
    depth: number
}

/**
 * è§„åˆ™è¿›å…¥æ¡ç›®
 */
interface RuleEnterEntry extends TraceEntryBase {
    type: 'rule-enter'
    ruleName: string
    tokenIndex: number
}

/**
 * è§„åˆ™é€€å‡ºæ¡ç›®
 */
interface RuleExitEntry extends TraceEntryBase {
    type: 'rule-exit'
    ruleName: string
    tokenIndex: number
    cacheHit: boolean
    duration?: number
}

/**
 * Token æ¶ˆè´¹æ¡ç›®
 */
interface TokenConsumeEntry extends TraceEntryBase {
    type: 'token-consume'
    tokenIndex: number
    tokenValue: string
    tokenName: string
    success: boolean
}

/**
 * è½¨è¿¹æ¡ç›®è”åˆç±»å‹
 */
type TraceEntry = RuleEnterEntry | RuleExitEntry | TokenConsumeEntry

/**
 * Subhuti Trace Debugger é»˜è®¤å®ç°ï¼ˆv2.0ï¼‰
 */
export class SubhutiTraceDebugger implements SubhutiDebugger {
    private trace: TraceEntry[] = []
    private depth = 0
    
    onRuleEnter(ruleName: string, tokenIndex: number): number {
        this.trace.push({
            type: 'rule-enter',
            ruleName,
            tokenIndex,
            depth: this.depth
        })
        this.depth++
        return performance.now()
    }
    
    onRuleExit(
        ruleName: string, 
        tokenIndex: number, 
        cacheHit: boolean,
        context?: unknown
    ): void {
        this.depth--
        
        let duration: number | undefined
        if (context !== undefined && typeof context === 'number') {
            duration = performance.now() - context
        }
        
        this.trace.push({
            type: 'rule-exit',
            ruleName,
            tokenIndex,
            cacheHit,
            duration,
            depth: this.depth
        })
    }
    
    onTokenConsume(
        tokenIndex: number,
        tokenValue: string,
        tokenName: string,
        success: boolean
    ): void {
        this.trace.push({
            type: 'token-consume',
            tokenIndex,
            tokenValue,
            tokenName,
            success,
            depth: this.depth
        })
    }
    
    getTrace(): string {
        const lines: string[] = []
        lines.push('ğŸ“‹ Rule Execution Trace')
        lines.push('')
        
        for (const entry of this.trace) {
            const indent = '  '.repeat(entry.depth)
            
            if (entry.type === 'rule-enter') {
                lines.push(`${indent}â†’ ${entry.ruleName} @${entry.tokenIndex}`)
            } else if (entry.type === 'rule-exit') {
                let exitInfo = `${indent}â† ${entry.ruleName} @${entry.tokenIndex}`
                
                if (entry.cacheHit) {
                    exitInfo += ' âš¡CACHED'
                }
                
                if (entry.duration !== undefined) {
                    exitInfo += ` (${entry.duration.toFixed(2)}ms)`
                }
                
                lines.push(exitInfo)
            } else if (entry.type === 'token-consume') {
                if (entry.success) {
                    const status = 'âœ“'
                    lines.push(`${indent}  ${status} ${entry.tokenName}="${entry.tokenValue}" @${entry.tokenIndex}`)
                }
            }
        }
        
        return lines.join('\n')
    }
    
    clear(): void {
        this.trace = []
        this.depth = 0
    }
}

// ============================================
// [3] SubhutiParserDebugger - è£…é¥°å™¨è°ƒè¯•å™¨
// ============================================

/**
 * è§„åˆ™æ‰§è¡Œè®°å½•
 */
export interface RuleExecution {
    type: 'enter' | 'exit'
    ruleName: string
    tokenIndex: number
    timestamp: number
    success?: boolean
    depth: number
}

/**
 * Or åˆ†æ”¯è®°å½•
 */
export interface OrBranchRecord {
    ruleName: string
    tokenIndex: number
    totalBranches: number
    triedBranches: Array<{
        index: number
        success: boolean
        tokensBefore: number
        tokensAfter: number
    }>
    successBranch?: number
    timestamp: number
}

/**
 * å›æº¯è®°å½•
 */
export interface BacktrackRecord {
    triggerRule: string
    fromTokenIndex: number
    toTokenIndex: number
    reason: string
    timestamp: number
}

/**
 * Token æ¶ˆè´¹è®°å½•
 */
export interface TokenConsumeRecord {
    tokenName: string
    tokenValue: string
    tokenIndex: number
    success: boolean
    ruleName: string
    timestamp: number
}

/**
 * å®Œæ•´çš„è°ƒè¯•æ•°æ®
 */
export interface DebugData {
    ruleExecutions: RuleExecution[]
    orBranches: OrBranchRecord[]
    backtracks: BacktrackRecord[]
    tokenConsumes: TokenConsumeRecord[]
    startTime: number
    endTime: number
}

/**
 * Parser è°ƒè¯•è£…é¥°å™¨
 */
export class SubhutiParserDebugger<T extends SubhutiParser = SubhutiParser> {
    private wrappedParser: T
    private data: DebugData
    private currentDepth: number = 0
    private startTime: number = 0
    
    constructor(ParserClass: new (...args: any[]) => T, tokens: SubhutiMatchToken[], ...args: any[]) {
        this.wrappedParser = new ParserClass(tokens, ...args) as T
        
        this.data = {
            ruleExecutions: [],
            orBranches: [],
            backtracks: [],
            tokenConsumes: [],
            startTime: 0,
            endTime: 0
        }
        
        this.wrapMethods()
    }
    
    private wrapMethods(): void {
        const parser = this.wrappedParser as any
        
        // åŒ…è£… subhutiRule
        const originalSubhutiRule = parser.subhutiRule.bind(parser)
        parser.subhutiRule = (targetFun: Function, ruleName: string, className: string) => {
            this.recordRuleEnter(ruleName, parser.tokenIndex)
            const result = originalSubhutiRule(targetFun, ruleName, className)
            this.recordRuleExit(ruleName, parser.tokenIndex, result !== undefined)
            return result
        }
        
        // åŒ…è£… Or
        const originalOr = parser.Or.bind(parser)
        parser.Or = (alternatives: SubhutiParserOr[]) => {
            const currentRule = parser.ruleStack[parser.ruleStack.length - 1] || 'unknown'
            const startTokenIndex = parser.tokenIndex
            
            const orRecord: OrBranchRecord = {
                ruleName: currentRule,
                tokenIndex: startTokenIndex,
                totalBranches: alternatives.length,
                triedBranches: [],
                timestamp: performance.now()
            }
            
            const wrappedAlternatives = alternatives.map((alt, index) => ({
                alt: () => {
                    const tokensBefore = parser.tokenIndex
                    alt.alt()
                    const tokensAfter = parser.tokenIndex
                    const success = !parser._parseFailed
                    
                    orRecord.triedBranches.push({
                        index,
                        success,
                        tokensBefore,
                        tokensAfter
                    })
                    
                    if (success) {
                        orRecord.successBranch = index
                    }
                }
            }))
            
            const result = originalOr(wrappedAlternatives)
            this.data.orBranches.push(orRecord)
            return result
        }
        
        // åŒ…è£… consumeToken
        const originalConsumeToken = parser.consumeToken.bind(parser)
        parser.consumeToken = (tokenName: string) => {
            const currentRule = parser.ruleStack[parser.ruleStack.length - 1] || 'unknown'
            const token = parser.curToken
            const tokenIndex = parser.tokenIndex
            
            const result = originalConsumeToken(tokenName)
            
            this.data.tokenConsumes.push({
                tokenName,
                tokenValue: token?.tokenValue || '',
                tokenIndex,
                success: result !== undefined,
                ruleName: currentRule,
                timestamp: performance.now()
            })
            
            return result
        }
        
        // åŒ…è£… restoreState
        const originalRestoreState = parser.restoreState.bind(parser)
        parser.restoreState = (backData: any) => {
            const currentRule = parser.ruleStack[parser.ruleStack.length - 1] || 'unknown'
            const fromIndex = parser.tokenIndex
            const toIndex = backData.tokenIndex
            
            if (fromIndex !== toIndex) {
                this.data.backtracks.push({
                    triggerRule: currentRule,
                    fromTokenIndex: fromIndex,
                    toTokenIndex: toIndex,
                    reason: `Backtrack in ${currentRule}`,
                    timestamp: performance.now()
                })
            }
            
            return originalRestoreState(backData)
        }
    }
    
    private recordRuleEnter(ruleName: string, tokenIndex: number): void {
        this.data.ruleExecutions.push({
            type: 'enter',
            ruleName,
            tokenIndex,
            timestamp: performance.now(),
            depth: this.currentDepth
        })
        this.currentDepth++
    }
    
    private recordRuleExit(ruleName: string, tokenIndex: number, success: boolean): void {
        this.currentDepth--
        this.data.ruleExecutions.push({
            type: 'exit',
            ruleName,
            tokenIndex,
            timestamp: performance.now(),
            success,
            depth: this.currentDepth
        })
    }
    
    get parser(): T {
        return this.wrappedParser
    }
    
    start(): void {
        this.data.startTime = performance.now()
        this.startTime = this.data.startTime
    }
    
    end(): void {
        this.data.endTime = performance.now()
    }
    
    getData(): DebugData {
        return this.data
    }
    
    clear(): void {
        this.data = {
            ruleExecutions: [],
            orBranches: [],
            backtracks: [],
            tokenConsumes: [],
            startTime: 0,
            endTime: 0
        }
        this.currentDepth = 0
    }
    
    static create<T extends SubhutiParser>(
        ParserClass: new (...args: any[]) => T,
        tokens: SubhutiMatchToken[],
        ...args: any[]
    ): T & SubhutiParserDebugger<T> {
        const debugger = new SubhutiParserDebugger(ParserClass, tokens, ...args)
        
        return new Proxy(debugger, {
            get(target, prop) {
                if (prop in target) {
                    return (target as any)[prop]
                }
                
                const parser = target.parser as any
                const value = parser[prop]
                
                if (typeof value === 'function') {
                    return value.bind(parser)
                }
                
                return value
            },
            
            set(target, prop, value) {
                const parser = target.parser as any
                parser[prop] = value
                return true
            }
        }) as T & SubhutiParserDebugger<T>
    }
}

// ============================================
// [4] SubhutiVisualizer - å¯è§†åŒ–å™¨
// ============================================

/**
 * è°ƒè¯•æ•°æ®ç±»å‹
 */
export interface VisualizerDebugData {
    ruleExecutions: Array<{
        type: 'enter' | 'exit'
        ruleName: string
        tokenIndex: number
        timestamp: number
        success?: boolean
    }>
    orBranches: Array<{
        ruleName: string
        totalBranches: number
        successBranch?: number
        tokenIndex: number
    }>
    tokenConsumes: Array<{
        tokenName: string
        tokenIndex: number
        success: boolean
    }>
    startTime: number
    endTime: number
}

/**
 * å¯è§†åŒ–é€‰é¡¹
 */
export interface VisualizerOptions {
    mode?: 'timeline' | 'or-branches' | 'token-compare' | 'full'
    maxDepth?: number
    highlightRules?: string[]
    showTimestamps?: boolean
    showTokenIndex?: boolean
}

/**
 * SubhutiParser å¯è§†åŒ–å™¨
 */
export class SubhutiVisualizer {
    /**
     * ç”Ÿæˆå®Œæ•´æŠ¥å‘Š
     */
    static generateReport(
        data: VisualizerDebugData,
        tokens: SubhutiMatchToken[],
        cst: SubhutiCst | undefined,
        options: VisualizerOptions = {}
    ): string {
        const {
            mode = 'full',
            maxDepth = Infinity,
            highlightRules = [],
            showTimestamps = false,
            showTokenIndex = true
        } = options
        
        const lines: string[] = []
        
        lines.push('â•'.repeat(80))
        lines.push('ğŸ” SubhutiParser è°ƒè¯•æŠ¥å‘Š')
        lines.push('â•'.repeat(80))
        lines.push('')
        
        lines.push(...this.generateSummary(data, tokens, cst))
        lines.push('')
        
        if (mode === 'timeline' || mode === 'full') {
            lines.push(...this.generateTimeline(data, { maxDepth, highlightRules, showTimestamps, showTokenIndex }))
            lines.push('')
        }
        
        if (mode === 'or-branches' || mode === 'full') {
            lines.push(...this.generateOrBranchesReport(data))
            lines.push('')
        }
        
        if (mode === 'token-compare' || mode === 'full') {
            lines.push(...this.generateTokenComparison(tokens, data.tokenConsumes, cst))
            lines.push('')
        }
        
        return lines.join('\n')
    }
    
    private static generateSummary(
        data: VisualizerDebugData,
        tokens: SubhutiMatchToken[],
        cst: SubhutiCst | undefined
    ): string[] {
        const lines: string[] = []
        const duration = data.endTime - data.startTime
        
        lines.push('ğŸ“Š æ€»ä½“ç»Ÿè®¡')
        lines.push('â”€'.repeat(80))
        lines.push(`  è§£æè€—æ—¶:     ${duration.toFixed(2)}ms`)
        lines.push(`  è¾“å…¥Tokenæ•°:  ${tokens.length}`)
        lines.push(`  è§„åˆ™æ‰§è¡Œæ•°:   ${data.ruleExecutions.length / 2}`)
        lines.push(`  Oråˆ†æ”¯æ•°:     ${data.orBranches.length}`)
        lines.push(`  Tokenæ¶ˆè´¹æ•°:  ${data.tokenConsumes.length}`)
        lines.push(`  è§£æçŠ¶æ€:     ${cst ? 'âœ… æˆåŠŸ' : 'âŒ å¤±è´¥'}`)
        
        return lines
    }
    
    static generateTimeline(
        data: VisualizerDebugData,
        options: Partial<VisualizerOptions> = {}
    ): string[] {
        const lines: string[] = []
        const { maxDepth = Infinity, highlightRules = [], showTimestamps = false, showTokenIndex = true } = options
        
        lines.push('ğŸ“ è§„åˆ™æ‰§è¡Œæ—¶é—´çº¿')
        lines.push('â•'.repeat(80))
        
        let currentDepth = 0
        
        for (const exec of data.ruleExecutions) {
            if (exec.type === 'exit') currentDepth--
            
            if (currentDepth >= maxDepth) {
                if (exec.type === 'enter') currentDepth++
                continue
            }
            
            const indent = '  '.repeat(currentDepth)
            const timestamp = showTimestamps ? `[${(exec.timestamp - data.startTime).toFixed(1)}ms]` : ''
            const tokenIdx = showTokenIndex ? `[${exec.tokenIndex}]` : ''
            const highlight = highlightRules.includes(exec.ruleName) ? 'ğŸ”' : ''
            
            if (exec.type === 'enter') {
                lines.push(`${indent}${timestamp}${tokenIdx} â†’ ${highlight}${exec.ruleName}`)
                currentDepth++
            } else {
                const status = exec.success ? 'âœ…' : 'âŒ'
                lines.push(`${indent}${timestamp}${tokenIdx} ${status} ${highlight}${exec.ruleName}`)
            }
        }
        
        return lines
    }
    
    static generateOrBranchesReport(data: VisualizerDebugData): string[] {
        const lines: string[] = []
        
        lines.push('ğŸ”€ Or åˆ†æ”¯é€‰æ‹©åˆ†æ')
        lines.push('â•'.repeat(80))
        
        if (data.orBranches.length === 0) {
            lines.push('  ï¼ˆæ²¡æœ‰ Or è§„åˆ™æ‰§è¡Œï¼‰')
            return lines
        }
        
        for (const orBranch of data.orBranches) {
            lines.push('')
            lines.push(`ğŸ“Œ ${orBranch.ruleName} @ token[${orBranch.tokenIndex}]`)
            lines.push(`   æ€»åˆ†æ”¯æ•°: ${orBranch.totalBranches}`)
            
            if (orBranch.successBranch !== undefined) {
                lines.push(`   âœ… æˆåŠŸåˆ†æ”¯: ${orBranch.successBranch}`)
            } else {
                lines.push(`   âŒ æ‰€æœ‰åˆ†æ”¯éƒ½å¤±è´¥`)
            }
        }
        
        return lines
    }
    
    static generateTokenComparison(
        inputTokens: SubhutiMatchToken[],
        tokenConsumes: Array<{ tokenName: string; tokenIndex: number; success: boolean }>,
        cst: SubhutiCst | undefined
    ): string[] {
        const lines: string[] = []
        
        lines.push('ğŸ” Token å®Œæ•´æ€§æ£€æŸ¥')
        lines.push('â•'.repeat(80))
        
        const meaningfulTokens = inputTokens.filter((t: any) => {
            const tokenName = t.tokenType?.name || t.tokenName || ''
            return tokenName !== 'SingleLineComment' &&
                tokenName !== 'MultiLineComment' &&
                tokenName !== 'Spacing' &&
                tokenName !== 'LineBreak'
        })
        
        const cstTokens = cst ? this.collectCSTTokens(cst) : []
        
        lines.push(`è¾“å…¥ Token æ•°: ${meaningfulTokens.length}`)
        lines.push(`CST Token æ•°:  ${cstTokens.length}`)
        lines.push(`æ¶ˆè´¹å°è¯•æ•°:    ${tokenConsumes.length}`)
        lines.push(`æ¶ˆè´¹æˆåŠŸæ•°:    ${tokenConsumes.filter(t => t.success).length}`)
        lines.push('')
        
        lines.push('è¯¦ç»†å¯¹æ¯”:')
        const missing: string[] = []
        
        for (let i = 0; i < meaningfulTokens.length; i++) {
            const inputToken = meaningfulTokens[i]
            const tokenValue = (inputToken as any).tokenValue || ''
            const found = cstTokens.includes(tokenValue)
            const status = found ? 'âœ…' : 'âŒ'
            
            if (!found) {
                missing.push(tokenValue)
            }
            
            lines.push(`  [${i}] ${status} "${tokenValue}"`)
        }
        
        if (missing.length > 0) {
            lines.push('')
            lines.push(`âš ï¸  ä¸¢å¤±çš„ Token (${missing.length}ä¸ª):`)
            missing.forEach(token => {
                lines.push(`     âŒ "${token}"`)
            })
        } else {
            lines.push('')
            lines.push('âœ… æ‰€æœ‰ Token éƒ½å·²ä¿ç•™ï¼')
        }
        
        return lines
    }
    
    private static collectCSTTokens(node: SubhutiCst): string[] {
        const tokens: string[] = []
        
        if (node.value !== undefined && (!node.children || node.children.length === 0)) {
            tokens.push(node.value)
        }
        
        if (node.children) {
            for (const child of node.children) {
                tokens.push(...this.collectCSTTokens(child))
            }
        }
        
        return tokens
    }
    
    static generateShortReport(
        data: VisualizerDebugData,
        tokens: SubhutiMatchToken[],
        cst: SubhutiCst | undefined
    ): string {
        const duration = data.endTime - data.startTime
        const status = cst ? 'âœ…' : 'âŒ'
        const ruleCount = data.ruleExecutions.length / 2
        const orCount = data.orBranches.length
        const tokenCount = data.tokenConsumes.filter(t => t.success).length
        
        return `${status} Parse ${duration.toFixed(2)}ms | ${ruleCount} rules | ${orCount} ors | ${tokenCount} tokens consumed | ${tokens.length} tokens total`
    }
}

